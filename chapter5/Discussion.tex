\chapter{General Discussion}
\chaptermark{Discussion}

The work I have done for this thesis does not, by any means, close the book on our understanding of selection in the house mouse, however, there are a number of useful insights that can be gleaned form my analyses. In this discussion I will start this describing the main insights to be take from my analyses. I will go on to describe several avenues for further research, suggested by my results. 

I have assumed that all CNEs share a single DFE which is a first approximation, but is unrealistic. The method used by Halligan et al (2013) to identify the CNEs I analysed throughout my thesis successfully identifies known regulatory features in the genome. There are multiple roles played by the CNEs identified using phastCons, or similar approaches. These include the regulation of gene expression and the control of alternate splicing. It seems reasonable to expect that these two classes of elements, which have very different biochemical roles, will be subject to different DFEs. Dividing up CNEs that have been identified using phylogenetic methods into different functional categories represents a challenge. Data of the kind generated by ENCODE could be used to assign biochemical function to CNEs identified using phylogenetic approaches, i.e. one could take the intersection of ENCODE data and phastCons elements.

\section{Soft and partial selective sweeps in mice}

	The work in this thesis has relied on the assumption of hard selective sweeps. Both the DFE-alpha and polyDFE analyses used in Chapters 3 and 4 assume that there selected mutations possess a single selection, unchangeable selection coefficient. However, it could be the case that when the environment changes, alleles that were once neutral become selectively advantageous or disadvantageous. Alleles that become advantageous in this manner and subsequently fix generate soft sweeps. The reductions in diversity between soft and hard sweeps produce distinct patterns of genetic diversity (Hermisson and Pennings?). 
	A major difference between soft sweeps and hard sweeps is in the distribution of haplotypes in the population after fixation. In the case of soft sweeps, the allele, when segregating neutrally, may be present on mut
	
	Schrider and Kern used a machine learning approach to classify regions of the human genome as having experinced a hard or soft sweep or being linked to a hard or soft sweep. They found that the 

\section{The interaction between natural selection and demographic history}

	This thesis has focussed on the effects of BGS and SSWs and has assumed, expect where explicitly modelled, that the demographic history of \textit{M. m. castaneus} has not influenced our analyses. This may influence the results of both Chapters 3 and 4 as the effects of, at least, BGS can become amplified under population size change (Hernandez paper). In Chapter 3 we inferred that \textit{M. m. castaneus} has recently undergone a dramatic population expansion, a result obtained from two quasi-independent classes of putatively neutral sites (Table REF). It is tempting to interpret these results in light of recent human history; since mice are commensal to humans their population numbers have likely exploded in the recent past (REF?). However, as we also showed in Chapter 3, selection at linked sites caused by DFE parameters estimated from the data cause one to infer a population expansion even there is not one. \textit{M. m. castaneus} may very well have undergone a rapid popualtion expansion in the recent past, but it is likely that the demographic parameters we inferred are highly affected by selection at linked sites.
	
	Across the \textit{M. m. castaneus} genome, there is a strongly negative Tajima's $D$ of around -0.5 (Figure REF), consistent with both widespread selection at linked sites and a recent population expansion (REF?). In Chapter 3 we showed that selection at linked sites generated by the DFEs we inferred from the mouse population data we analysed, do not result in such negative Tajima's $D$ values. Even when we modelled relatively strong selection ($\gamma_a = 400$), SSWs resulted in a localised trough in Tajima's $D$ around protein-coding exons but it recovered almost to 0 in surrounding regions (Figure REF). This suggests, then, that the seemingly genome-wide negative Tajima's D is not explained by the effects of selection at linked sites, though of course there may be selection parameters that do generate the observed Tajima's $D$ values. Additionally, it could be that relatively recent demographic processes have erased the signal of selection at linked sites in SFS across the genome, but to fully investigate this, estimates of the demographic history for mice, unbiased by the effects of selection at linked sites are required and there are number of strategies that could be employed to determine this.
	
	Since demographic models assume neutrality, it is necessary to parametrise them from regions of the genome that are free from the effects of selection at linked sites. One could use regions of the genome far from functional elements, that experience high recombination rates. Regions free from conserved elements (both coding and non-coding) may be free from the effects of selection at sites, especially if the are highly recombining. One could go a step further and fit a model of selection at linked sites to genome-wide polymorphism data (e.g. using the methods of Elyashiv or Hammer) and identify regions that have only experience minuscule  effects of selection. However, such methods rely on a perfect knowledge of the locations of functional elements in the genome. Since the methods used to identify conserved elements may fail to detect rapidly evolving sequences, there is the possibility that there are BGS and SSW effects present even when there are no annotations present. An alternative strategy would be to use the machine learning methods of Schrider and Kern (2016). S/HIC builds a classifier that can discriminate between neutrally evolving sequneces and sequnqce that are influencesd by selection at linked sites by `learning` from extensive simulations, what neutrally evolving sequences look like and identify them from a combination of numerous summary statistics. Parametrising demographic models from the neutrally evolving sequences identified using the 

Neutralome, Elyashiv, S/HIC, find regions of the genome that appear to be evolving neutrally and use them to parametrise demographic models. Are demographic models too simplistic?

\section{Making use of more of the available data}

In Chapters 3 and 4 I used methods to estimate the distribution of fitness effects by analysis of the uSFS. Both methods I used, DFE-alpha and polyDFE, make use of a putatively neutral class of sites to account for distortions in the uSFS away from neutral expectation caused by processes other than the direct effects of selection. In the case of DFE-alpha, an explicit demographic model is fit to the neutral uSFS, while polyDFE uses the neutral sites' uSFS to estimate a set of  nuisance parameters.  However, processes other than population size change can distort the uSFS, such as selection at linked sites, so by not explicitly modelling selection at linked sites, both the demographic correction applied in DFE-alpha analyses and the nuisance parameters in polyDFE essentially throw away information. 

A substantial hurdle to population genomic research is in making use of all the available data. For example, in Chapters 3 and 4 we have analysed either the site frequency spectrum or nucleotide diversity. These are just two data summaries that be analysed in a population genetic model. As we demonstrated in Chapter 4, the SFS is a useful summary of the data that can be used to very accurately estimate the dDFE, but the uSFS is pretty poor for estimating the parameters of strongly selected advantageous mutations particularly if they are rare. In such cases, patterns of genetic diversity are perhaps more informative. Ideally one would make use of information present both the uSFS for potentially selected sites, whilst simultaneously modelling the reductions in neutral diversity caused by said selection. One possibility for such an enterprise would be in performing approximate Bayesian computation (ABC) with forward-in-time population genetic simulations.

The basic idea is as follows: Simulate data under a model, sampling the parameters of interest from  plausible ranges, and compare summary statistics from your dataset to those obtained by simulation \citep{RN356}. The parameter sets that generated summary statistics most resembling those in your data are an estimate of the true parameters. In the context of inferring the dDFE and positive selection parameters, one could simulate a chromosome or chromosomal regions with the same structure as the species of interest (like we did in Chapter 3). Many thousands of different combinations of DFE parameters could be simulated and from these simulations, one could extract summary statistics for the site frequency spectrum, linkage disequilibrium and haplotype structure within, and in the regions surrounding, multiple classes of functional elements. The biggest difficulty in applying an analysis such as this the computational demands of the many, many simulations required.

The simulations used in this thesis were performed with SLiM (v1.8), a program which was, at the time of its release, among the most computationally efficient forward-in-time simulators available \cite{RN148}. Forward simulators have historically been much slower than coalescent simulators as the evolution of whole chromosomes is typically tracked. In the original SLiM publication, Messer described how by tracking just the simulated mutations, simulations of purifying selection acting on a whole human chromosome (100Mbp long; $10^4$ diploid individuals; for $10^5$ generations) took just 4 days. As impressive as that is, it in infeasible that ABC could be performed using such simulations. In the four years since starting my PhD a number of increasingly efficient forward-in-time simulators have been developed \citep{RN362, RN360, RN361}, but even with these it would be infeasible to perform ABC of the kind described. However, very recent advances in computational efficiency of forward-in-time simulators \citep{RN359} may bring ABC of the kind outlined within reach.




\section{Moving beyond mice}

	Recombination rates in other rodents, patterns of gentic diversity.

Mice are an excellent model organism for studies of mammalian molecular evolution. Obviously, the genomic resources available for mice (reference genome, annotations  kit available for studies in mice is close to unrivalled. 
However, it remains to be seen whether the conclusions that we reached in this thesis can be generalised to other organisms. 

Something about comparing the Nam et al(2017) analysis with the proposed analysis.
 
Throughout this thesis, we have examined evidence for molecular evolution at several levels; from the very broad (e.g. looking at the correlation between recombination rate and genetic diversity in Chapter 2) to the very precise (analysis of the uSFS in Chapter 3). In this thesis we have come to a number of conclusions. 

In Chapter 4 we used parameters of selection obtained by analysing patterns of genetic diversity, to try and answer one of evolutionary biology's long-standing questions: Do mutations in protein-coding or regulatory regions of the genome contribute more to adaptive evolution? We found that protein-coding regions do appear to contribute more to adaptive evolution by virtue of the increased selection pressure on protein-changing variants. It remains to be seen whether 

